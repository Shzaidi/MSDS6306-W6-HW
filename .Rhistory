sort(MyData, Educ)
boxplot(Income2005 ~ Educ + Subject)
boxplot(Income2005 ~ Educ)
boxplot(formula = (Income2005/1000) ~ Educ)
plot(Income2005/1000, Subject)
plot(Income2005/1000, Educ)
plot(Income2005/1000 ~ Educ)
plot(Income2005/1000 ~ sort(Educ, a))
?sort
plot(Income2005/1000 ~ sort(Educ, decreasing=FALSE))
plot(Income2005/1000 ~ Educ[<12])
plot(Income2005/1000 ~ Educ["<12"])
summary(MyData)
AnovaComputation <- lm(formula = Income2005 ~ Educ, data = MyData)
summary(AnovaComputation)
names(mydata)
head(mydata)
?attach
detach(mydata)
detach(mydata)
head(mydata)
sessionInfo()
install.packages("bootstrap")
library(bootstrap)
mydata <-read.csv(choose.file(), header=T, sep",")
head(mydata)
mydata <-read.csv(choose.file(), header=T, sep",")
mydata <-read.csv(c("./Rating.csv"), header=T, sep",")
getwd()
mydata <- read.csv(c("./Rating.csv"), header=T, sep",")
mydata <- read.csv("./Rating.csv", header=T, sep",")
?read.csv
mydata <- read.csv(Rating.csv, header=T, sep",")
head(mydata)
MTData1 <- read.csv(Rating.csv, header=T, sep",")
getwd()
list.files()
myMTdata1 <- read.csv(Rating.csv)
library(ggplot2)
library(stats)
?choose.files
myMTdata1 <- read.csv(choose.file(Rating.csv), header=T, sep=",")
library(utils)
myMTdata1 <- read.csv(choose.file(Rating.csv), header=T, sep=",")
myMTdata1 <- read.csv(choose.file(), header=T, sep=",")
install.packages("mosaic")
install.packages("Sleuth3")
require(Sleuth3)
require(mosaic)
trellis.par.set(theme = col.mosaic())
options(digits digits = 4)
options(digits = 4)
Summary(case0701)
summary(case0701)
histogram(~Velocity, type = density, density = TRUE, nint 10, data = case0701)
histogram(~Velocity, type = "density", density = TRUE, nint 10, data = case0701)
histogram(~Velocity, type = "density", density = TRUE, nint = 10, data = case0701)
histogram(~Velocity,  density = TRUE, nint = 10, data = case0701)
histogram(~Distance,  density = TRUE, nint = 10, data = case0701)
xyplot(Distance ~ Velocity, type = c("p", "r"))
xyplot(Distance ~ Velocity, type = c("p", "r"), data = cas0701)
xyplot(Distance ~ Velocity, type = c("p", "r"), data = case0701)
lm1 = lm(Distance ~ Velocity), data = case0701)
lm1 = lm(Distance ~ Velocity, data = case0701)
summary(lm1)
histogram(~Velocity,  density = TRUE, nint = 5, data = case0701)
histogram(~Velocity,  density = TRUE, nint = 20, data = case0701)
histogram(~Velocity,  density = FALSE, nint = 20, data = case0701)
histogram(~Velocity,  density = TRUE, nint = 20, data = case0701)
histogram(~Velocity,  density = TRUE, nint = 10, data = case0701)
xyplot(Distance ~ Velocity, type = c("p", "r"), data = case0701)
xyplot(Distance ~ Velocity, panel = panel.lmbands, data = case0701)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
SM <- c(data8$Mass)
TC <- c(data8$Tcell)
cor(SM, TC)
Fit <- lm(TC ~ SM)
summary(Fit)
histogram(~Mass,  density = TRUE, nint = 10, data = data8)
histogram(~Tcell,  density = TRUE, nint = 10, data = data8)
xyplot(Tcell ~ Mass, type = c("p", "r"), data = data8)
xyplot(Tcell ~ Mass, panel = panel.lmbands, data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass"
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(0.1, 0.60),
xlim = c(2, 11),
frame.plot=FALSE,
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(0.1, 0.60),
xlim = c(2, 11),
frame.plot=FALSE,
col = ifelse(TcellResponse > 0.35, "red", "blue"),
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(0.1, 0.60),
xlim = c(2, 11),
frame.plot=FALSE,
col = ifelse(Tcell > 0.35, "red", "blue"),
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(0.1, 0.60),
xlim = c(2, 11),
frame.plot=FALSE,
col = ifelse(TC > 0.35, "red", "blue"),
data = data8)
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
anova(Fit)
newdata = data.frame(Mass=5.91)
predict(Fit, newdata, interval = "predict")
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
cor(SM, TC)
confint(Fit, level = 0.95)
?confint
?confint
anova(Fit)
yplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(-0.1, 0.60),
xlim = c(2, 10),
frame.plot = FALSE,
col = ifelse(TC > 0.35, "red", "blue"),
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(-0.1, 0.60),
xlim = c(2, 10),
frame.plot = FALSE,
col = ifelse(TC > 0.35, "red", "blue"),
data = data8)
par(mfrow = c(1,2))
qqnorm(Fit$residuals)
plot(Fit$fitted, Fit$residuals)
newdata = data.frame(Mass = 5.91)
predict(Fit, newdata, interval = "predict")
predict(Fit, newdata, interval = "confidence")
head(data8)
?distribution
?boot
install.packages("boot")
?boot
??boot
library(ggplot2)
library(stats)
library(utils)
library(boot)
x <- c(187, 169, 123, 166, 199, 127, 159, 155, 145, 142, 171)
y <- c(122, 45, 98, 38, 148, 179, 193, 54, 22, 245)
n1 <- length(x)
n2 <- length(y)
k <- 100000
set.seed(1234)
simXsample <- replicate(k, rnorm(n1, mean(x), sd(x)))
simYsample <- replicate(k, rnorm(n2, mean(y), sd(y)))
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
quantile(simMeanDifs, c(0.025 , 0.975)
quantile(simMeanDifs, c(0.025 , 0.975)
?quantile
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
quantile(simMeanDifs, c(0.025 , 0.975)
Hist(simMeanDifs, col="red", nclass=30)
Hist(simMeanDifs, col="red", nclass=30)
hist(simMeanDifs, col="red", nclass=30)
quantile(simMeanDifs, c(0.025,0.975))
quantile(simMeanDifs, c(0.005,0.995))
hist(simMeanDifs, col="red", nclass=10)
hist(simMeanDifs, col="red", nclass=50)
summary(x)
summary(y)
summary(simMeanDifs)
summary (x - y)
difs <- x - y
summary(simXsample)
summary(simMeanDifs)
lambda1 <- 1 / mean(x)
lambda2 <- 1/ mean(y)
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
quantile(simMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
set.seed(9876)
k <- 100000
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
# Compute mean differences of n1 & n2 simulated observations k times:
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
hist(simExpMeanDifs, col="blue", nclass=50)
hist(simExpMeanDifs, col="blue", nclass=150)
# Non-parametric bootstrap
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample <- replicate(k, sample(Day2Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
Day3Waiting <- c(155.6, 347.5, 678.0, 893.0, 233.4, 134.8, 167.4)
L3 <- length(Day3Waiting)
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample2 <- replicate(k, sample(Day3Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs1vs3 <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample2, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs1vs3, c(0.025,0.975))
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
install.packages("boot")
library(ggplot2)
library(stats)
library(utils)
library(boot)
# Assignment DDS - Week 4
# Write bootstrap code to illustrate the Central Limit
#   Theorem in R markdown and push result to GitHub.
# • Use a normal distribution with two different sample
#   sizes and an exponential distribution with two different
#   sample sizes.
# • Correct code alone is insufficient. Please also comment
#    the code and explain the results.
# • For help, see the lotsa.medians function in Unit 2.
# • Send link to GitHub repo to live session instructor.
# Sample Data
x <- c(187, 169, 123, 166, 199, 127, 159, 155, 145, 142, 171)
y <- c(122, 45, 98, 38, 148, 179, 193, 54, 22, 245)
n1 <- length(x)
n2 <- length(y)
# Set number of Simulations
k <- 100000
# define seed number such that the following computations
# can be replicated or reproduced
set.seed(9876)
# Simulate or Bootstrap with replacement by repliocating from
# k samples of n1 & n2 normal distributions with the right means and variances
# Also called the Parametric Bootstrap:
simXsample <- replicate(k, rnorm(n1, mean(x), sd(x)))
simYsample <- replicate(k, rnorm(n2, mean(y), sd(y)))
# Compute mean differences of n1 & n2 simulated observations k times:
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
# Plot
hist(simMeanDifs, col="red", nclass=50)
summary(simMeanDifs)
####################################################################
# if we use rexp() function instead of rnorm that signifies that
# our the differences or any other function derived from x & y (eg. area)
# is non-linear, in which case the confidence interval could be computed
# with different approaches :
# 1) simulation
# 2) analytical
# 3) theoretical derivations
# these being computationally intensive , we use simulation here:
########++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Call Center waiting times on 2 different days. We want to know if there
# is material difference in response time over these 2 sample days with
# small sample available. Also , for one of the days, fewer observations
# are available.
# For random time observations, an exponential distribution is the best
# applicable :
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
Day3Waiting <- c(155.6, 347.5, 678.0, 893.0, 233.4, 134.8, 167.4)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
L3 <- length(Day3Waiting)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
# Compute mean differences of n1 & n2 simulated observations k times:
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
# Plot
hist(simExpMeanDifs, col="blue", nclass=150)
##################################################################################
# Non-parametric bootstrap
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample <- replicate(k, sample(Day2Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
# Variation on day3
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample2 <- replicate(k, sample(Day3Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs1vs3 <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample2, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs1vs3, c(0.025,0.975))    # i.e. 95% Confidence Interval
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
install.packages("boot")
install.packages(c("rj", "rj.gd"), repos = "http://download.walware.de/rj-2.0")
library(ggplot2)
library(utils)
library(stats)
N <- 10000
graphics.off()
par(mfrow = c(1,2), pty = "s")
for(k in 1:20) {
m <- (rowMeans(matrix(runif(M*k), N, k)) - 0.5)*sqrt(12*k)
hist(m, breaks = "FD", xlim = c(-4,4), main = k,
prob = TRUE, ylim = c(0,0.5), col = "lemonchiffon")
pu <- par("usr")[1:2]
x <- seq(pu[1], pu[2], len = 500)
lines(x, dnorm(x), col = "red")
qqnorm(m, ylim = c(-4,4), xlim = c(-4,4), pch = ".", col = "blue")
abline(0, 1, col = "red")
Sys.sleep(1)
}
m<-numeric(10000);
for(k in (1:20))
{
for(i in(1:10000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(100000);
for(k in (1:20))
{
for(i in(1:100000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(10000);
p<-0.75; for(j in (1:50))
{ k<-j*j
for(i in(1:10000))
{m[i]<-(mean(rbinom(k,1,p))-p)/sqrt(p*(1-p)/k)}
hist(m,breaks=41,xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(10000);
for(k in (1:20))
{
for(i in(1:10000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
lambda <- 0.2   # exponential parameter
nsim <- 1000    # number of simulations
n <- 40         # number of points exponentially distributed
# seed for random simulation
set.seed(4)
# creating data "sim" and "sim_mean"
sim <- matrix(rexp(n * nsim, lambda), nrow=nsim, ncol=n)
sim_mean <- rowMeans(sim) # "rowMeans" is faster then "apply".
data_mean <- mean(sim_mean)
data_var <- var(sim_mean)
print(c(data_mean, data_var))
theory_mean <- 1/lambda
theory_var <- (1/lambda)^2/n
print(c(theory_mean, theory_var))
data <- data.frame(sim_mean);
plot2 <- ggplot(data, aes(x=sim_mean, colour=Distributions));
plot2 <- ggplot(data, aes(x=sim_mean, colour=Distributions));
plot2 <- plot2 + geom_histogram(aes(y=..density.., colour = "Data"),
fill= "lightcyan3", binwidth=0.2) +
# Theoretical (red) and Simulated mean (green)
geom_vline(xintercept=theory_mean, colour="red",   linetype="dashed", size=1) +
geom_vline(xintercept=data_mean,   colour="green", linetype="dashed", size=1) +
# Normal distribution with mean/variance Theoretical (red) and Simulated (green)
stat_function(fun=dnorm, args=list(mean=theory_mean, sd=sqrt(theory_var)),
aes(colour = "Theoretical"), size = 1.0) +
stat_function(fun=dnorm, args=list(mean=data_mean, sd=sqrt(data_var)),
aes(colour = "Simulated"), size = 1.0) +
# Title,labels and legend
scale_colour_manual(values = c("lightseagreen", "red", "green")) +
labs(title="Comparison between simulated and theoretical data", x="Means", y="Density")
print(plot2)
library(ggplot2)
library(stats)
library(ggplot2)
library(stats)
library(dtplyr)
library(data.table)
library(rmarkdown)
library(plotrix)
library(tutorial)
rm(list = ls())
objects()
getwd()
setwd("C:\\Users\\najee\\Documents\\R\\MSDS6306-W6-HW")
GDPData <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
GDPData2 <- GDPData[-c(1:4,195:330), -c(3,6,7:10)]
names(GDPData2) <- c("ID", "Ranking", "Country", "GDP")
str(GDPData2)
EduData <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
names(EduData) <- c("ID","Country","Income_Group", "Region", "Lending_Group", "Other")
dim(EduData)[1]
str(EduData)
GDPDataList <- GDPData2[,c(1,3)]
row.names(GDPDataList) <- NULL
B <- GDPDataList[order(GDPDataList$ID),]
EduDataList <- EduData[,c(1,2)]
row.names(EduDataList) <- NULL
A <- EduDataList[order(EduDataList$ID),]
dim(B)
dim(A)
N <- dim(A)[1]
N
n <- dim(B)[1]
n
# Implementing a double loop by column to check for equal values in two tables and write check results in a new DF table with Country Names and Check columns
DF <- data.frame(ID=rep("", N), Country=rep("", N), Check=rep("", N),stringsAsFactors=FALSE)
for (i in 1:N)
{
j <- 1
while (j <= n)
{
if (A[i,1] == B[j,1])
{
DF[i,1] = A[i,1]
DF[i,2] = A[i,2]
DF[i,3] = "yes"
i <- i + 1
break
} else
{
DF[i,1] = A[i,1]
DF[i,2] = A[i,2]
DF[i,3] = "no"
j <- j + 1
}
}
}
Exclusion = subset(DF, Check == "no")
row.names(Exclusion) <- NULL
Exclusion2 <- Exclusion[,c(1,2)]
Exclusions2
Exclusion2
EduData2 <- EduData[,c(1:3)]
row.names(EduData2) = NULL
Data <- merge(GDPData2, EduData2, by = "ID", all = TRUE)
dim(Data)[1]
answ1 <- length(Data$GDP)
message("Number of countries for which both data type are available is: ", answ1)
str(DF)
length(DF$Check == "yes")
length(DF$Check == "no")
