data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
anova(Fit)
newdata = data.frame(Mass=5.91)
predict(Fit, newdata, interval = "predict")
library(ggplot2)
library(lme4)
library(lattice)
library(mosaic)
data8 <- read.csv(choose.files(), header = TRUE, sep = ",")
head(data8)
Fit <- lm(Tcell ~ Mass, data = data8)
summary(Fit)
cor(SM, TC)
confint(Fit, level = 0.95)
?confint
?confint
anova(Fit)
yplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(-0.1, 0.60),
xlim = c(2, 10),
frame.plot = FALSE,
col = ifelse(TC > 0.35, "red", "blue"),
data = data8)
xyplot(Tcell ~ Mass,
panel = panel.lmbands,
main = "T-Cell Response vs Stone Mass",
xlab = "Stone Mass (g)",
ylab = "Health level or T-Cell Response (mm)",
ylim = c(-0.1, 0.60),
xlim = c(2, 10),
frame.plot = FALSE,
col = ifelse(TC > 0.35, "red", "blue"),
data = data8)
par(mfrow = c(1,2))
qqnorm(Fit$residuals)
plot(Fit$fitted, Fit$residuals)
newdata = data.frame(Mass = 5.91)
predict(Fit, newdata, interval = "predict")
predict(Fit, newdata, interval = "confidence")
head(data8)
?distribution
?boot
install.packages("boot")
?boot
??boot
library(ggplot2)
library(stats)
library(utils)
library(boot)
x <- c(187, 169, 123, 166, 199, 127, 159, 155, 145, 142, 171)
y <- c(122, 45, 98, 38, 148, 179, 193, 54, 22, 245)
n1 <- length(x)
n2 <- length(y)
k <- 100000
set.seed(1234)
simXsample <- replicate(k, rnorm(n1, mean(x), sd(x)))
simYsample <- replicate(k, rnorm(n2, mean(y), sd(y)))
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
quantile(simMeanDifs, c(0.025 , 0.975)
quantile(simMeanDifs, c(0.025 , 0.975)
?quantile
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
quantile(simMeanDifs, c(0.025 , 0.975)
Hist(simMeanDifs, col="red", nclass=30)
Hist(simMeanDifs, col="red", nclass=30)
hist(simMeanDifs, col="red", nclass=30)
quantile(simMeanDifs, c(0.025,0.975))
quantile(simMeanDifs, c(0.005,0.995))
hist(simMeanDifs, col="red", nclass=10)
hist(simMeanDifs, col="red", nclass=50)
summary(x)
summary(y)
summary(simMeanDifs)
summary (x - y)
difs <- x - y
summary(simXsample)
summary(simMeanDifs)
lambda1 <- 1 / mean(x)
lambda2 <- 1/ mean(y)
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
quantile(simMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
set.seed(9876)
k <- 100000
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
# Compute mean differences of n1 & n2 simulated observations k times:
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
hist(simExpMeanDifs, col="blue", nclass=50)
hist(simExpMeanDifs, col="blue", nclass=150)
# Non-parametric bootstrap
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample <- replicate(k, sample(Day2Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
Day3Waiting <- c(155.6, 347.5, 678.0, 893.0, 233.4, 134.8, 167.4)
L3 <- length(Day3Waiting)
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample2 <- replicate(k, sample(Day3Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs1vs3 <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample2, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs1vs3, c(0.025,0.975))
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
install.packages("boot")
library(ggplot2)
library(stats)
library(utils)
library(boot)
# Assignment DDS - Week 4
# Write bootstrap code to illustrate the Central Limit
#   Theorem in R markdown and push result to GitHub.
# • Use a normal distribution with two different sample
#   sizes and an exponential distribution with two different
#   sample sizes.
# • Correct code alone is insufficient. Please also comment
#    the code and explain the results.
# • For help, see the lotsa.medians function in Unit 2.
# • Send link to GitHub repo to live session instructor.
# Sample Data
x <- c(187, 169, 123, 166, 199, 127, 159, 155, 145, 142, 171)
y <- c(122, 45, 98, 38, 148, 179, 193, 54, 22, 245)
n1 <- length(x)
n2 <- length(y)
# Set number of Simulations
k <- 100000
# define seed number such that the following computations
# can be replicated or reproduced
set.seed(9876)
# Simulate or Bootstrap with replacement by repliocating from
# k samples of n1 & n2 normal distributions with the right means and variances
# Also called the Parametric Bootstrap:
simXsample <- replicate(k, rnorm(n1, mean(x), sd(x)))
simYsample <- replicate(k, rnorm(n2, mean(y), sd(y)))
# Compute mean differences of n1 & n2 simulated observations k times:
simMeanDifs <- apply(simXsample, 2, mean) - apply(simYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
# Plot
hist(simMeanDifs, col="red", nclass=50)
summary(simMeanDifs)
####################################################################
# if we use rexp() function instead of rnorm that signifies that
# our the differences or any other function derived from x & y (eg. area)
# is non-linear, in which case the confidence interval could be computed
# with different approaches :
# 1) simulation
# 2) analytical
# 3) theoretical derivations
# these being computationally intensive , we use simulation here:
########++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Call Center waiting times on 2 different days. We want to know if there
# is material difference in response time over these 2 sample days with
# small sample available. Also , for one of the days, fewer observations
# are available.
# For random time observations, an exponential distribution is the best
# applicable :
Day1Waiting <- c(23.6, 42.9, 53.4, 73.4, 1.6, 2.4, 13.6, 2.1)
Day2Waiting <- c(15.6, 34.5, 67.0, 89.0, 2.4, 1.8, 16.4)
Day3Waiting <- c(155.6, 347.5, 678.0, 893.0, 233.4, 134.8, 167.4)
L1 <- length(Day1Waiting)
L2 <- length(Day2Waiting)
L3 <- length(Day3Waiting)
lambda1 <- 1 / mean(Day1Waiting)
lambda2 <- 1/ mean(Day2Waiting)
simXsample_exp <- replicate(k, rexp(L1, lambda1))
simYsample_exp <- replicate(k, rexp(L2, lambda2))
# Compute mean differences of n1 & n2 simulated observations k times:
simExpMeanDifs <- apply(simXsample_exp, 2, mean) - apply(simYsample_exp, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(simExpMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
quantile(simExpMeanDifs, c(0.005,0.995))    # i.e. 99% Confidence Interval
# Plot
hist(simExpMeanDifs, col="blue", nclass=150)
##################################################################################
# Non-parametric bootstrap
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample <- replicate(k, sample(Day2Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs, c(0.025,0.975))    # i.e. 95% Confidence Interval
# Variation on day3
NPsimXsample <- replicate(k, sample(Day1Waiting, replace = TRUE))
NPsimYsample2 <- replicate(k, sample(Day3Waiting, replace = TRUE))
# Compute mean differences of n1 & n2 simulated observations k times:
NPsimMeanDifs1vs3 <- apply(NPsimXsample, 2, mean) - apply(NPsimYsample2, 2, mean)
# find the two relevant quantiles of k simulated mean differences
quantile(NPsimMeanDifs1vs3, c(0.025,0.975))    # i.e. 95% Confidence Interval
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
source('~/R/Working_for_bootstrap_assignment_w4.R', encoding = 'ASCII')
install.packages("boot")
install.packages(c("rj", "rj.gd"), repos = "http://download.walware.de/rj-2.0")
library(ggplot2)
library(utils)
library(stats)
N <- 10000
graphics.off()
par(mfrow = c(1,2), pty = "s")
for(k in 1:20) {
m <- (rowMeans(matrix(runif(M*k), N, k)) - 0.5)*sqrt(12*k)
hist(m, breaks = "FD", xlim = c(-4,4), main = k,
prob = TRUE, ylim = c(0,0.5), col = "lemonchiffon")
pu <- par("usr")[1:2]
x <- seq(pu[1], pu[2], len = 500)
lines(x, dnorm(x), col = "red")
qqnorm(m, ylim = c(-4,4), xlim = c(-4,4), pch = ".", col = "blue")
abline(0, 1, col = "red")
Sys.sleep(1)
}
m<-numeric(10000);
for(k in (1:20))
{
for(i in(1:10000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(100000);
for(k in (1:20))
{
for(i in(1:100000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(10000);
p<-0.75; for(j in (1:50))
{ k<-j*j
for(i in(1:10000))
{m[i]<-(mean(rbinom(k,1,p))-p)/sqrt(p*(1-p)/k)}
hist(m,breaks=41,xlim=c(-4,4),main=sprintf("%d",k))
}
m<-numeric(10000);
for(k in (1:20))
{
for(i in(1:10000))
{m[i]<-(mean(runif(k))-0.5)*sqrt(12*k)}
hist(m,breaks=0.3*(-15:15),xlim=c(-4,4),main=sprintf("%d",k))
}
lambda <- 0.2   # exponential parameter
nsim <- 1000    # number of simulations
n <- 40         # number of points exponentially distributed
# seed for random simulation
set.seed(4)
# creating data "sim" and "sim_mean"
sim <- matrix(rexp(n * nsim, lambda), nrow=nsim, ncol=n)
sim_mean <- rowMeans(sim) # "rowMeans" is faster then "apply".
data_mean <- mean(sim_mean)
data_var <- var(sim_mean)
print(c(data_mean, data_var))
theory_mean <- 1/lambda
theory_var <- (1/lambda)^2/n
print(c(theory_mean, theory_var))
data <- data.frame(sim_mean);
plot2 <- ggplot(data, aes(x=sim_mean, colour=Distributions));
plot2 <- ggplot(data, aes(x=sim_mean, colour=Distributions));
plot2 <- plot2 + geom_histogram(aes(y=..density.., colour = "Data"),
fill= "lightcyan3", binwidth=0.2) +
# Theoretical (red) and Simulated mean (green)
geom_vline(xintercept=theory_mean, colour="red",   linetype="dashed", size=1) +
geom_vline(xintercept=data_mean,   colour="green", linetype="dashed", size=1) +
# Normal distribution with mean/variance Theoretical (red) and Simulated (green)
stat_function(fun=dnorm, args=list(mean=theory_mean, sd=sqrt(theory_var)),
aes(colour = "Theoretical"), size = 1.0) +
stat_function(fun=dnorm, args=list(mean=data_mean, sd=sqrt(data_var)),
aes(colour = "Simulated"), size = 1.0) +
# Title,labels and legend
scale_colour_manual(values = c("lightseagreen", "red", "green")) +
labs(title="Comparison between simulated and theoretical data", x="Means", y="Density")
print(plot2)
library(ggplot2)
library(stats)
colour <- c("khaki1","khaki3","khaki4","indianred2","firebrick1")
col.list <- rep(0, length(Data3$Income_Group))
col.list[Data3$Income_Group=="Low income"] <- 1
col.list[Data3$Income_Group=="Lower middle income"] <-2
col.list[Data3$Income_Group=="Upper middle income"] <- 3
col.list[Data3$Income_Group=="High income: nonOECD"] <- 4
col.list[Data3$Income_Group=="High income: OECD"] <- 5
op<-par(mar=c(3.0, 3.0, 1.5, 1.5))
plot(GDP/1000000, bty="l", col=c(colour[col.list]), pch=19, axes = FALSE, xlab="", ylab="")
title(main="Distribution of GDP Countries by Income Group", col.main="indianred4", sub="Source: Elaboration on World Bank Data", col.sub="grey", font.sub=3)
pts <- pretty(GDP / 1000000, n=10)
axis(2, at = pts, las = 1)
box()
title(ylab = "GDP ($bn)", line = 2)
par(op)
text(20, 15, "Low Income", pos = 3, xpd = F, col="khaki1", vfont = NULL, font = 2, cex=1,2, offset=0, adj = c(0,0))
text(20, 14.5, "Lower Middle Income", pos = 3, xpd = F, col="khaki3", vfont = NULL, font = 2, cex=1.2, offset=0, adj = c(0,0))
text(20, 14, "Upper Middle Income", pos = 3, xpd = F, col="khaki4", vfont = NULL, font = 2, cex=1,2, offset=0, adj = c(0,0))
text(20, 13.5, "High Income [Non OECD]", pos = 3, xpd = F, col="indianred2", vfont = NULL, font = 2, cex=1.2, offset=0, adj = c(0,0))
text(20, 13, "High Income [OECD]", pos = 3, xpd = F, col="firebrick1", vfont = NULL, font = 2, cex=1.2, offset=0, adj = c(0,0))
textbox(c(54,60),1.8, "[54] Malta ", cex=1, col="indianred2", border="black", font=2)
textbox(c(68,78),1.8, "[68] Iceland ", cex=1, col="indianred2", border="black", font=2)
textbox(c(103,112),1.8, "[103] Kenya", cex=1, col=" khaki1", border="black", font=2)
textbox(c(131,145),1.8, "[131] Bangladesh", cex=1, col=" khaki1", border="black", font=2)
textbox(c(136,144),3.2, "[136] Qatar", cex=1, col=" indianred2", border="black", font=2)
textbox(c(177,188),1.8, "[177] Indonesia", cex=1, col=" khaki3", border="black", font=2)
textbox(c(150,160),2, "[150] Thailand", cex=1, col=" khaki3", border="black", font=2)
textbox(c(188,195),8.2, "[188] China", cex=1, col=" khaki3", border="black", font=2)
# And close chart
# Adding tables with Top and Bottom 10 countries by GDP
# This would provide space for a 3X2 chart table with first row merged
# nf <- layout(matrix(c(1,1,2,3), 2, 2, byrow=TRUE), respect=TRUE)
# layout.show(nf)
# This instead is just what we need for our purposes
Data4 <- Data3[order(Data3$Ranking), ]
TopData4 <- Data4[c(1:10), c(2:4,6)]
row.names(TopData4)<-NULL
names(TopData4)<-c("Ranking","Country","GDP ($m)", "Income Group")
WorstData4 <- Data4[c(180:180), c(2:4,6)]
row.names(WorstData4)<-NULL
names(WorstData4)<-c("Ranking","Country","GDP ($m)", "Income Group")
par(mfrow=c(2,1), oma=c(0,0,2,0))
plot(1,type='n', axes=F, xlab="", ylab="")
title(main="Highest", col.main="indianred4")
addtable2plot(0.6,0.2,TopData4,bty="o",display.rownames=FALSE,hlines=TRUE,vlines=TRUE)
plot(1,type='n', axes=F, xlab="", ylab="")
title(main="Lowest", col.main="indianred4")
addtable2plot(0.6 ,0.2,TopData4,bty="o",display.rownames=TRUE,hlines=TRUE,vlines=TRUE)
title("Highest and Lowest GDP Countries ??? Ranking & Income Group Status", outer=TRUE, cex=1.2, col="blue", font=3)
# And close
rm(list = ls())
objects()
getwd()
setwd("C:\\Users\\najee\\Documents\\R\\MSDS6306-W6-HW")
library(ggplot2)
library(stats)
library(dtplyr)
library(tabplot)
library(rmarkdown)
# Data reading:
# File 1
####GDPData
GDPData <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv ", header = TRUE, sep = ",", stringsAsFactors = FALSE)
GDPData2 <- GDPData[-c(1:4,195:330), -c(3,6,7:10)]
names(GDPData2) <- c("ID","Ranking","Country", "GDP")
head(GDPData2, 13)
tail(GDPData2, 13)
dim(GDPData2)[1]
# File 2
EduData <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
names(EduData) <- c("ID","Country","Income_Group", "Region", "Lending_Group", "Other")
dim(EduData)[1]
str(EduData)
head(EduData, 13)
tail(EduData, 13)
# ********************************************
# find Exclusions of countries whose IDs do not match between 2 files
GDPDataList <- GDPData2[,c(1,3)]
row.names(GDPDataList) <- NULL
B <- GDPDataList[order(GDPDataList$ID),]
EduDataList <- EduData[,c(1,2)]
row.names(EduDataList) <- NULL
A <- EduDataList[order(EduDataList$ID),]
dim(B)
dim(A)
N <- dim(A)[1]
N
n <- dim(B)[1]
n
# Implementing a double loop by column to check for equal values in two tables and write check results in a new DF table with Country Names and Check columns
DF <- data.frame(ID = rep("", N), Country = rep("", N), Check = rep("", N),stringsAsFactors = FALSE)
for (i in 1:N)  {
j <- 1
while (j <= n)
{
if (A[i,1] == B[j,1])
{
DF[i,1] = A[i,1]
DF[i,2] = A[i,2]
DF[i,3] = "yes"
i <- i + 1
break
} else
{
DF[i,1] = A[i,1]
DF[i,2] = A[i,2]
DF[i,3] = "no"
j <- j + 1
}
}
}
# fix(DF) #And close
Exclusion = subset(DF, Check == "no")
row.names(Exclusion) <- NULL
Exclusion2 <- Exclusion[,c(1,2)]
Exclusion2
# ******************************************
# Q1 Match on cty-code. How many match ?
EduData2 <- EduData[,c(1:3)]
row.names(EduData2) = NULL
Data <- merge(GDPData2, EduData2, by = "ID")
dim(Data)[1]
answ1 <- length(Data$ID)
message("Number of countries for which both data type are available is: ", answ1)
# 189 records with country code but names are still mixed strings
# *********************************************
# Question 2: Sort the data frame in ascending order by GDP rank.
# What is the 13th country in the resulting data frame?
# Ensuring GDP is captured as numeric vector and is not in
# scientific format in the dataframe
sapply(Data, class)
typeof(Data$GDP)
Data$GDP <- gsub("\\,","", Data$GDP)
GDP <- Data$GDP
Data2 <- transform(Data, GDP = as.numeric(as.character(GDP)))
typeof(Data2$GDP)
# Sorting data frame as requested and displaying and storing answer 2
sort.Data2 <- Data2[order(Data2$GDP), ]
#Store sorted GDP Data in a dataframe
SortedGdpRankData2 <- data.frame(sort.Data2)
head(SortedGdpRankData2, 15)
answ2 <- SortedGdpRankData2[13,5]
message("The 13th country by GDP ranked in ascending order is: ", answ2)
# *******************************************************
# Question 3: What are the average GDP rankings
# for the "High income: OECD" and "High income: nonOECD" groups?
# Ensuring also the Ranking attribute is captured as numeric
# vector and verifying that no further missing values are for
# the attributes in scope for the rest of the exercise
# SortedGdpRankData2
Ranking <- SortedGdpRankData2$Ranking
Data3 <- transform(SortedGdpRankData2, Ranking = as.numeric(as.character(Ranking)))
head(Data3, 15)
answ3.1 <- with(Data3, mean(Ranking[Income_Group == "High income: OECD"]))
message("The avg GDP Ranking for High income: OECD countries is: ", round(answ3.1, 2))
answ3.2 <- with(Data3, mean(Ranking[Income_Group == "High income: nonOECD"]))
message("The avg GDP Ranking for High income: Non-OECD countries is: ", round(answ3.2, 2))
# *************************************
# Question 4: Plot the GDP for all of the countries. Use ggplot2 to color your plot by Income Group
head(SortedGdpRankData2, 15)
str(SortedGdpRankData2)
library(tabplot)
tableplot(SortedGdpRankData2)
tableplot(SortedGdpRankData2, select = c(GDP))
# Chart 1:
c1 <- plot(SortedGdpRankData2$GDP, bty = "l", col = "green", pch = 19, main = "GDP distribution", xlab = "Countries (asc. order)", ylab = "GDP in $m")
# Convert GDP Sacaling
GdpScaledToBillion <- SortedGdpRankData2$GDP/1000000
# Chart plot with Corrected GDP Scale and identifying top 4 outliers
op <- par(mar = c(5,5,4,2) + 0.5)
plot(GdpScaledToBillion, bty = "l", col = "blue", pch = 18, axes = FALSE, xlab = "", ylab = "")
title(main = "GDP Per Country", col.main = "red", lines.main = 14, sub = "Source: Elaboration on World Bank Data", col.sub = "grey") ##lines.sub = 4, font.sub = 3
axis(1)
pts <- pretty(GdpScaledToBillion, n = 10)
axis(2, at = pts, las = 1)
box()
title(ylab = "GDP ($bn)", line = 2)
title(xlab = "Sequence of Countries", line = 2)
par(op)
text(182, 16.1, "US", pos = 3, xpd = F, col = "black", vfont = NULL, font = 2, cex = 0.6, offset = 0)
text(180, 8.1, "CHN", pos = 3, xpd = F, col = "black", vfont = NULL, font = 2, cex = 0.6, offset = 0)
text(178, 5.85, "JPN", pos = 3, xpd = F, col = "black", vfont = NULL, font = 2, cex = 0.6, offset = 0)
text(176, 3.35, "DEU", pos = 3, xpd = F, col = "black", vfont = NULL, font = 2, cex = 0.6, offset = 0)
text(8, 0.3, "Tuvalu ($40mm)", pos = 3, xpd = F, col = "black", vfont = NULL, font = 2, cex = 0.6, offset = 0, adj = 1)
colour <- c("grey", "yellow","orange","red","black")
col.list <- rep(0, length(SortedGdpRankData2$Income_Group))
col.list[SortedGdpRankData2$Income_Group == "Low income"] <- 1
col.list[SortedGdpRankData2$Income_Group == "Lower middle income"] <- 2
col.list[SortedGdpRankData2$Income_Group == "Upper middle income"] <- 3
col.list[SortedGdpRankData2$Income_Group == "High income: nonOECD"] <- 4
col.list[SortedGdpRankData2$Income_Group == "High income: OECD"] <- 5
p <- plot(GdpScaledToBillion, pch = 19, main = "GDP per Income Group", xlab = "Countries (asc. Order)", ylab = "GDP in $m", col = c(colour[col.list]))
legend(x = "topleft", cex = 0.7, c(" Low income in Grey ",
" Lower middle income in Yellow ",
" Upper middle income in Orange ",
" High_income_Non_OECD in Red ",
" High_income_OECD in Black "))
# And close chart
tableplot(SortedGdpRankData2)
c1 <- plot(SortedGdpRankData2$GDP, bty = "l", col = "green", pch = 19, main = "GDP distribution", xlab = "Countries (asc. order)", ylab = "GDP in $tr")
tableplot(SortedGdpRankData2, select = c(GDP))
GdpScaledToBillion <- SortedGdpRankData2$GDP/1000000
c1 <- plot(SortedGdpRankData2$GDP, bty = "l", col = "green", pch = 19, main = "GDP distribution", xlab = "Countries (asc. order)", ylab = "GDP in $tr")
c1 <- plot(SortedGdpRankData2$GDP, bty = "l", col = "green", pch = 19, main = "GDP distribution", xlab = "Countries (asc. order)", ylab = "GDP in $tr")
c1 <- plot(GdpScaledToBillion, bty = "l", col = "green", pch = 19, main = "GDP distribution", xlab = "Countries (asc. order)", ylab = "GDP in $m")
tail(GDPData2, 13)
